### Vector Database - ChromaDB
https://docs.trychroma.com/getting-started


### Weaviate Plugin
https://weaviate.io/blog/weaviate-retrieval-plugin


### Kinetica
https://www.kinetica.com/
https://www.kinetica.com/features/sqlgpt/


## PDF QA
Using redis as vector database
https://github.com/malywut/gpt_examples
https://github.com/mayooear/gpt4-pdf-chatbot-langchain


## Evaluations of LLM - Harrison Chase - CEO Langchain

## Guard Rails AI
Framework for creating custom validators
Text to SQL using Guardrails
https://shreyar.github.io/guardrails/use_cases/text2sql/text2sql/


## llmaindex
LLM Powered Query Engine
https://github.com/jerryjliu/llama_index

LLmaindex Colab
https://colab.research.google.com/drive/12cdBWMpOfCxpiAS1zSqZRY66o84qMiTo?usp=sharing#scrollTo=690a6918-7c75-4f95-9ccc-d2c4a1fe00d7

Query Transformation    
- Single-Step Query Decomposition  
Some recent approaches (e.g. self-ask, ReAct) have suggested that LLM’s perform better at answering complex questions when they break the question into smaller steps. We have found that this is true for queries that require knowledge augmentation as well.

If your query is complex, different parts of your knowledge base may answer different “subqueries” around the overall query.
- Multi-Step Query Transformations   
https://gpt-index.readthedocs.io/en/v0.5.27/how_to/query/query_transformations.html

GPT Primer
https://gpt-index.readthedocs.io/en/latest/guides/primer/usage_pattern.html


## 
https://www.swyx.io/


## Alternative Embeddings
 https://www.youtube.com/watch?v=ogEalPMUCSY
# Instructors Embeedings from Hugging Face